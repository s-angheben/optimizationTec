{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPY165cDDJTz"
   },
   "source": [
    "# Lab. 2: Stochastic global optimization\n",
    "\n",
    "## Introduction\n",
    "\n",
    "#### <u>The goal of this laboratory is to study the application of stochastic global search algorithms on different benchmark functions.</u>\n",
    "\n",
    "We will study two methods:\n",
    "- *DIRECT*\n",
    "- *Basin-hopping*\n",
    "\n",
    "Moreover, we will study the effect of their parameters on the outcome of the search.\n",
    "\n",
    "---\n",
    "\n",
    "Getting started: the following code cell contains the core functions that we will use. Hence, **remember to run it every time the runtime is reconnected**.\n",
    "\n",
    "You can find a wrapper function for the  two algorithm, together with a wrapper for the benchmark function.\n",
    "As regards the *OptFun* class, the constructor takes as input a benchmark function (we will see later what functions are available). The relevant methods  are 4:\n",
    "1.   *Minima*: return the minimum of the function. The position can be obtained by the parameter *position* and the function value from the *score* parameter.\n",
    "2.   *Bounds*: returns where the function is defined\n",
    "3.   *Heatmap*: show a heatmap of the function highlighting the points visited by the local search (use with 2d function)\n",
    "4.   *plot*: show the trend of the points visited by the local search (use with 1d function)\n",
    "5.   *trend*: show the best points find during the optmization process.\n",
    "\n",
    "Each instance of *OptFun* stores the history of the point at which the function has been evaluated. The history is never cleaned and can be obtained through *OptFun.history*. Hence, if you reuse the class instance remember to clean the history (*OptFun.history = list()*).\n",
    "\n",
    "---\n",
    "\n",
    "The benchmark functions available comes from the *benchmark_functions* library (imported as *bf*).\n",
    "Example of the functions that can be used are the *Hypersphere*, the *Rastrign* the *DeJong5* and the Keane.\n",
    "The complete list of functions available can be found at this [link](https://gitlab.com/luca.baronti/python_benchmark_functions) or you can print it with *dir(bf)*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Czm90e6dDNxa"
   },
   "source": [
    "#### Base code to run every time the runtime is reconnected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 999,
     "status": "ok",
     "timestamp": 1709841654724,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "k9t_QSgtDGjU"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "try:\n",
    "  import benchmark_functions as bf\n",
    "  from scipydirect import minimize as spdirect\n",
    "except:  # colab env\n",
    "  !pip install benchmark_functions\n",
    "  !pip install scipydirect\n",
    "  import benchmark_functions as bf\n",
    "  from scipydirect import minimize as spdirect\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import basinhopping as spbasinhopping\n",
    "import inspect\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1709841654725,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "3hAGFGMlDQcY"
   },
   "outputs": [],
   "source": [
    "class OptFun():\n",
    "    def __init__(self, wf):\n",
    "        self.f = wf\n",
    "        self.history = []\n",
    "\n",
    "    def __call__(self, x0):\n",
    "        self.history.append(deepcopy(x0))\n",
    "        return self.f(x0)\n",
    "\n",
    "    def minima(self):\n",
    "        \"\"\"\n",
    "        Returns a list of Optimum objects of the known global minima. If there aren't any minima, an empty list value will be returned instead;\n",
    "\n",
    "        Returns:\n",
    "        - List of objects of class \"benchmark_functions.functions_info_loader.Optimum\"\n",
    "        - For each object:\n",
    "          - Access to 'position' parameter to get the axis values\n",
    "          - Access to 'score' parameter to get the value of the function\n",
    "        \"\"\"\n",
    "        return self.f.minima()\n",
    "\n",
    "    def bounds(self):\n",
    "        return self._convert_bounds(self.f.suggested_bounds())\n",
    "\n",
    "    def heatmap(self, fn = None):\n",
    "        plt.clf()\n",
    "        resolution = 50\n",
    "        fig = plt.figure()\n",
    "        fig.canvas.manager.set_window_title('Benchmark Function: '+self.f._name)\n",
    "        fig.suptitle(self.f._name)\n",
    "        bounds_lower, bounds_upper = self.f.suggested_bounds()\n",
    "        x = np.linspace(bounds_lower[0], bounds_upper[0], resolution)\n",
    "        if self.f._n_dimensions>1:\n",
    "            y = np.linspace(bounds_lower[1], bounds_upper[1], resolution)\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            Z = np.asarray([[self.f((X[i][j],Y[i][j])) for j in range(len(X[i]))] for i in range(len(X))])\n",
    "\n",
    "        plt.contour(x,y,Z,15,linewidths=0.5,colors='k') # hight lines\n",
    "        plt.contourf(x,y,Z,15,cmap='viridis', vmin=Z.min(), vmax=Z.max()) # heat map\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label('z')\n",
    "        if len(self.history)>0:\t# plot points\n",
    "            xdata = [x[0] for x in self.history]\n",
    "            xdata = xdata[1:]\n",
    "            ydata = [x[1] for x in self.history]\n",
    "            ydata = ydata[1:]\n",
    "\n",
    "            plt.plot(xdata, ydata, \"or-\", markersize=5, linewidth=1.5)\n",
    "            plt.plot(xdata[0], ydata[0], marker='X', markersize=13, color='black')\n",
    "\n",
    "            plt.plot(xdata[-1], ydata[-1], marker='P', markersize=13,color='white')\n",
    "            # TODO\n",
    "            # - bigger markersize for initial and final point + diff color\n",
    "            # - check f vs func\n",
    "            # - check num iter vs how many points are being plotted\n",
    "        if fn is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(fn, dpi=400)\n",
    "\n",
    "    def plot(self):\n",
    "        plt.clf()\n",
    "        values = [self.f(v) for v in self.history]\n",
    "        values = values[1:]\n",
    "        min = func.minima()[0].score\n",
    "\n",
    "        plt.plot(values, label=\"Scores\",marker='o')\n",
    "\n",
    "        plt.axhline(min, color=\"r\", label=\"optimum\", linestyle='dashed')\n",
    "        plt.xlabel('Iterations/Evaluations')  # TODO\n",
    "        plt.ylabel('f(x)')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def _convert_bounds(self, bounds):\n",
    "        new_bounds= []\n",
    "        for i in range(len(bounds[0])):\n",
    "            new_bounds.append((bounds[0][i], bounds[1][i]))\n",
    "        return new_bounds\n",
    "\n",
    "    def current_calls(self):\n",
    "        return len(self.history)\n",
    "\n",
    "def grid_search(f: OptFun, step_size=None, number_of_steps=None, minimization=True):\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the grid_search algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - step_size: the step size\n",
    "    - number_of_steps: the total number of steps\n",
    "    - minimization: boolean, True if looking for minimum, False if looking for maximum; defauls True\n",
    "\n",
    "    Returns:\n",
    "    - best value found\n",
    "    \"\"\"\n",
    "\n",
    "    if (step_size != None):\n",
    "      range_step_size = step_size\n",
    "    elif (number_of_steps != None):\n",
    "        range_step_size = int(np.floor(np.sqrt(number_of_steps)))\n",
    "    else:\n",
    "        print(\"Please provide at least the step_size or the number_of_steps\")\n",
    "        return\n",
    "\n",
    "    bounds = f.bounds()\n",
    "    best = float('inf') if minimization else float('sup')\n",
    "\n",
    "    for x in np.arange(bounds[0][0], bounds[0][1], range_step_size):\n",
    "      for y in np.arange(bounds[1][0], bounds[1][1], range_step_size):\n",
    "        current = f([x, y])\n",
    "        if minimization:\n",
    "          if current < best:\n",
    "            best = current\n",
    "        else:\n",
    "          if current > best:\n",
    "            best = current\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def direct(f: OptFun, eps: float = 1e-4, maxiter: int = 1000, maxfneval: int = 1000, optima: int = None, error_tollerance: int = None):\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the DIRECT algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - eps: regulates the trade-off between local and global exploration.\n",
    "            The smaller the eps, the finer the granularity of the search.\n",
    "    - maxiter: maximum number of iterations\n",
    "    -\n",
    "    \"\"\"\n",
    "    bounds = f.bounds()\n",
    "    results =  spdirect(\n",
    "        func,\n",
    "        bounds=bounds,\n",
    "        eps=eps,\n",
    "        maxT=maxiter,\n",
    "        maxf=maxfneval,\n",
    "        fglobal=-1e100,\n",
    "        fglper=0.001,\n",
    "        volper=-1.0,\n",
    "        sigmaper=-1.0\n",
    "    )\n",
    "    history = [func.f(v) for v in func.history]\n",
    "    history = history[1:]\n",
    "    best_score = min(history)\n",
    "    best_position = func.history[history.index(best_score)]\n",
    "    return results, best_position, best_score\n",
    "\n",
    "\n",
    "def basinhopping(\n",
    "    f: OptFun,\n",
    "    x0: np.ndarray,\n",
    "    T: float = 1.0,\n",
    "    stepsize: float = 0.5,\n",
    "    stepsize_interval: int = 50,\n",
    "    maxiter: int = 1000):\n",
    "    \"\"\"\n",
    "    Optimizes a function by using the Basin-hopping algorithm.\n",
    "\n",
    "    - f: function to optimize, an instance of OptFun\n",
    "    - x0: starting point for the search process\n",
    "    - T: temperature parameter\n",
    "    - stepsize: maximum step size for random displacement\n",
    "    - stepsize_interval: interval for the update of the step size\n",
    "    - maxiter: maximum number of iterations\n",
    "    \"\"\"\n",
    "    return spbasinhopping(\n",
    "        f,\n",
    "        x0,\n",
    "        niter=maxiter,\n",
    "        T=T,\n",
    "        stepsize=stepsize,\n",
    "        minimizer_kwargs=None,\n",
    "        take_step=None,\n",
    "        accept_test=None,\n",
    "        callback=None,\n",
    "        interval=stepsize_interval,\n",
    "        disp=False,\n",
    "        niter_success=None,\n",
    "        seed=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1709841654725,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "lPVkBFXeG-Mv"
   },
   "outputs": [],
   "source": [
    "def printClassInitArgs(class_obj):\n",
    "    print(f'{class_obj.name()}')\n",
    "    signature = inspect.signature(class_obj.__init__).parameters\n",
    "    print(\"-------------------------------\")\n",
    "    for name, parameter in signature.items():\n",
    "        if name != 'opposite':\n",
    "            print(\"Name: \", name, \"\\nDefault value:\", parameter.default)\n",
    "            #print(\"Annotation:\", parameter.annotation, \"\\nKind:\", parameter.kind)\n",
    "            print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQMoNUgSDTbj"
   },
   "source": [
    "# Exercises\n",
    "\n",
    "#### Solve the following exercises, and answer these questions at the end:\n",
    "\n",
    "- How do the approaches seen in today's lab compare to the one seen in the previous lab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91,
     "status": "ok",
     "timestamp": 1709841654725,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "fbF-V__PHGPk",
    "outputId": "7c73f133-472b-473f-d318-8ee84dce14e9"
   },
   "outputs": [],
   "source": [
    "# BE AWARE: check the arguments each benchmark function takes\n",
    "# if you're not sure, you can check the arguments by using the printClassInitArgs function\n",
    "print(dir(bf))\n",
    "printClassInitArgs(bf.Hypersphere())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mucSZghNDWCL"
   },
   "source": [
    "## Exercise 1/2: DIRECT\n",
    "In this first exercise we will use [DIRECT](https://scipydirect.readthedocs.io/en/latest/reference.html) as a search algorithm\n",
    "\n",
    "### Questions\n",
    "- How does the eps parameter influence the search process?\n",
    "- How does the number of maximum iterations influence the search process? (To note: the maximum iterations and maximum number of evalutions are the soly metrics used to reach a stopping condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1709841656248,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "cCKNQaaSDTma",
    "outputId": "c107162c-7370-45b7-fef2-250ff0808143"
   },
   "outputs": [],
   "source": [
    "func = OptFun(bf.EggHolder())  # TODO: try differenct benchmark function\n",
    "eps = 0.1  # TODO: try different values\n",
    "max_iter = 300  # TODO: try different values\n",
    "max_eval = 100  # TODO try different values\n",
    "\n",
    "res, best_location, best_value = direct(func, eps, max_iter, max_eval)\n",
    "print(\"Best value:\", best_value)\n",
    "print(\"Best location:\", best_location)\n",
    "\n",
    "func.heatmap()\n",
    "func.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kvWwb0tDbSZ"
   },
   "source": [
    "## Exercise 2/2: BASIN-HOPPING\n",
    "In this exercise we will use [Basin-hopping](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.basinhopping.html) as a search algorithm\n",
    "\n",
    "### Questions\n",
    "- What is the influence of the following parameters on the search process?\n",
    "  - **T:** The “temperature” parameter for the acceptance or rejection criterion. Higher “temperatures” mean that larger jumps in function value will be accepted. For best results T should be comparable to the separation (in function value) between local minima;\n",
    "  - **stepsize:** Maximum step size for use in the random displacement;\n",
    "  - **stepsize_interval:** interval for how often to update the stepsize;\n",
    "  - **niter:** The number of basin-hopping iterations.\n",
    "- How does the number of maximum iterations influence the search process?\n",
    "- How does the starting point influence the search process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1709841656590,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "AD_oevi5DVJS",
    "outputId": "7d59e529-8bba-4f53-e8d6-7b39e000a7a7"
   },
   "outputs": [],
   "source": [
    "func = OptFun(bf.EggHolder())  # TODO: try differenct benchmark functions\n",
    "x_0 = [-300, 200]  # set it appropriate for the funch used\n",
    "T = 10  # TODO: try different values\n",
    "stepsize = 0.1  # TODO: try different values\n",
    "stepsize_interval = 10  # TODO: try different values\n",
    "n_iter = 20  # TODO: try different values\n",
    "\n",
    "res = basinhopping(func, x_0, T, stepsize, stepsize_interval, n_iter)\n",
    "best_value, best_location = res['fun'], res['x']\n",
    "print(\"Best value:\", best_value)\n",
    "print(\"Best location:\", best_location)\n",
    "\n",
    "func.heatmap()\n",
    "func.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lphxcGsFDjbT"
   },
   "source": [
    "## Final questions\n",
    "- How do the approaches seen in today's lab compare to the one seen in the previous lab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1709841656590,
     "user": {
      "displayName": "Elia Cunegatti",
      "userId": "03325257844566684991"
     },
     "user_tz": -60
    },
    "id": "XR0d_Yi8DkXy"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
